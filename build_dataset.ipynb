{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZE = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_resize_and_save(filename, output_dir, bbox, size=SIZE):\n",
    "    \"\"\"Resize the image contained in `filename` and save it to the `output_dir`\"\"\"\n",
    "    image = Image.open(filename)\n",
    "    shape = image.size\n",
    "    x1 = max(bbox[0]-16, 0)\n",
    "    y1 = max(bbox[1] - 16, 0)\n",
    "    x2 = min(bbox[2] + 16, shape[0])\n",
    "    y2 = min(bbox[3] + 16, shape[1])\n",
    "    new_box = (x1, y1, x2, y2)\n",
    "    image = image.crop(box = new_box)\n",
    "    # Use bilinear interpolation instead of the default \"nearest neighbor\" method\n",
    "    image = image.resize((size, size), Image.BILINEAR)\n",
    "    image.save(os.path.join(output_dir, filename.split('/')[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 7/11329 [00:00<03:11, 59.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: output dir stanford-cars/car_ims_2562/ already exists\n",
      "Warning: dir stanford-cars/car_ims_2562/train_cars already exists\n",
      "Processing train data, saving preprocessed data to stanford-cars/car_ims_2562/train_cars\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11329/11329 [03:19<00:00, 56.75it/s]\n",
      "  0%|          | 3/2428 [00:00<01:30, 26.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dev data, saving preprocessed data to stanford-cars/car_ims_2562/dev_cars\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2428/2428 [00:45<00:00, 72.29it/s]\n",
      "  0%|          | 8/2428 [00:00<00:42, 57.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test data, saving preprocessed data to stanford-cars/car_ims_2562/test_cars\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2428/2428 [00:39<00:00, 54.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done building dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Define the data directories\n",
    "    project_dir = '~/Documents/Senior/CS230/Project/stanford-cars/'\n",
    "    data_dir = 'stanford-cars/'\n",
    "    output_dir = 'stanford-cars/car_ims_227/'\n",
    "    \n",
    "    # Train/dev/test split\n",
    "    # 70-15-15 stratified split by class\n",
    "    annotations = pd.read_csv(os.path.join(project_dir,'full_annotations.csv'), index_col = 0)\n",
    "    X = annotations[['relative_im_path', 'bbox_x1', 'bbox_y1', 'bbox_x2', 'bbox_y2']]\n",
    "    y = annotations[['class']]\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=1, stratify = y)\n",
    "    X_dev, X_test, y_dev, y_test = train_test_split(X_val, y_val, test_size=0.5, random_state=1, stratify = y_val)\n",
    "    \n",
    "    train_filenames = list(X_train['relative_im_path'])\n",
    "    dev_filenames = list(X_dev['relative_im_path'])\n",
    "    test_filenames = list(X_test['relative_im_path'])\n",
    "    \n",
    "    filenames = {'train': train_filenames,'dev': dev_filenames,'test': test_filenames}\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.mkdir(output_dir)\n",
    "    else:\n",
    "        print(\"Warning: output dir {} already exists\".format(output_dir))\n",
    "\n",
    "    # Preprocess train, dev and test\n",
    "    for split in ['train', 'dev', 'test']:\n",
    "        output_dir_split = os.path.join(output_dir, '{}_cars'.format(split))\n",
    "        if not os.path.exists(output_dir_split):\n",
    "            os.mkdir(output_dir_split)\n",
    "        else:\n",
    "            print(\"Warning: dir {} already exists\".format(output_dir_split))\n",
    "\n",
    "        print(\"Processing {} data, saving preprocessed data to {}\".format(split, output_dir_split))\n",
    "        for filename in tqdm(filenames[split]):\n",
    "            new_filename = os.path.join(data_dir, filename)\n",
    "            row = annotations.loc[annotations['relative_im_path']==filename]\n",
    "            x1 = int(row['bbox_x1'])\n",
    "            y1 = int(row['bbox_y1'])\n",
    "            x2 = int(row['bbox_x2'])\n",
    "            y2 = int(row['bbox_y2'])\n",
    "            box = (x1, y1, x2, y2)\n",
    "            crop_resize_and_save(new_filename, output_dir_split, box, size=SIZE)\n",
    "\n",
    "    print(\"Done building dataset\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
